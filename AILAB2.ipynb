{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Import Libraries"
      ],
      "metadata": {
        "id": "oJjPw1d-nwep"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oSG5brzmmpDP"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from typing import List"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Sentence Preprocessing"
      ],
      "metadata": {
        "id": "Ff9rYGj9n21V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sentences(text: str) -> List[str]:\n",
        "    sentences = re.split(r'[.!?]\\s*', text.strip())\n",
        "    sentences = [re.sub(r'[^a-z0-9\\s]', '', s.lower()).strip() for s in sentences if s.strip()]\n",
        "    return sentences"
      ],
      "metadata": {
        "id": "ZovBiQSLnARU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Word Preprocessing"
      ],
      "metadata": {
        "id": "Q4XkmAetn8XF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_words(text: str) -> List[str]:\n",
        "    text = re.sub(r'[^a-z0-9\\s]', '', text.lower())\n",
        "    return text.split()"
      ],
      "metadata": {
        "id": "tUlOWOBYnAUS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Levenshtein Distance"
      ],
      "metadata": {
        "id": "l5msdC9EoAsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def levenshtein_distance(s1: str, s2: str) -> int:\n",
        "    m, n = len(s1), len(s2)\n",
        "    if m == 0: return n\n",
        "    if n == 0: return m\n",
        "\n",
        "    dp = [[0]*(n+1) for _ in range(m+1)]\n",
        "    for i in range(m+1): dp[i][0] = i\n",
        "    for j in range(n+1): dp[0][j] = j\n",
        "\n",
        "    for i in range(1, m+1):\n",
        "        for j in range(1, n+1):\n",
        "            cost = 0 if s1[i-1] == s2[j-1] else 1\n",
        "            dp[i][j] = min(dp[i-1][j]+1, dp[i][j-1]+1, dp[i-1][j-1]+cost)\n",
        "    return dp[m][n]"
      ],
      "metadata": {
        "id": "caFCfLfynAW6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Sentence Similarity"
      ],
      "metadata": {
        "id": "8I4t1yZXoFaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_similarity(s1: str, s2: str) -> float:\n",
        "    if len(s1) == 0 and len(s2) == 0:\n",
        "        return 1.0\n",
        "    distance = levenshtein_distance(s1, s2)\n",
        "    return 1 - (distance / max(len(s1), len(s2)))"
      ],
      "metadata": {
        "id": "0vEt_IYsnAZv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Plagiarism Detection"
      ],
      "metadata": {
        "id": "NUYFHenIoJYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_plagiarism(doc1_text: str, doc2_text: str, threshold: float=0.7):\n",
        "    doc1_sentences = preprocess_sentences(doc1_text)\n",
        "    doc2_sentences = preprocess_sentences(doc2_text)\n",
        "\n",
        "    matched_sentences = 0\n",
        "    total_sentences = len(doc1_sentences)\n",
        "\n",
        "    print(\"\\nSentence Alignment and Similarity:\\n\")\n",
        "    for i, s1 in enumerate(doc1_sentences):\n",
        "        best_similarity = 0\n",
        "        best_j = -1\n",
        "        for j, s2 in enumerate(doc2_sentences):\n",
        "            sim = sentence_similarity(s1, s2)\n",
        "            if sim > best_similarity:\n",
        "                best_similarity = sim\n",
        "                best_j = j\n",
        "\n",
        "        status = \"Potential Plagiarism\" if best_similarity >= threshold else \"\"\n",
        "        if status: matched_sentences += 1\n",
        "\n",
        "        print(f\"Doc1 [{i}]: {s1}\")\n",
        "        print(f\"Doc2 [{best_j}]: {doc2_sentences[best_j] if best_j >=0 else '---'}\")\n",
        "        print(f\"Similarity: {best_similarity*100:.2f}% {status}\")\n",
        "        print(\"-\"*60)\n",
        "\n",
        "    plagiarism_percentage = (matched_sentences / total_sentences) * 100\n",
        "    print(f\"\\nOverall Plagiarism Percentage: {plagiarism_percentage:.2f}%\")"
      ],
      "metadata": {
        "id": "VSTgbS5enAcf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Example Execution"
      ],
      "metadata": {
        "id": "24tz3m8CoNtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    doc1 = \"\"\"Artificial Intelligence is a branch of computer science.\n",
        "    It deals with creating intelligent agents.\n",
        "    Agents perceive their environment and take actions.\n",
        "    AI includes machine learning and deep learning.\"\"\"\n",
        "\n",
        "    doc2 = \"\"\"Artificial Intelligence is a field of computer science.\n",
        "    It focuses on creating smart agents.\n",
        "    Agents perceive environment and act accordingly.\n",
        "    AI covers machine learning and deep learning.\"\"\"\n",
        "\n",
        "    detect_plagiarism(doc1, doc2, threshold=0.7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBoLOmZQnAfi",
        "outputId": "8563f894-7a69-46d3-9727-3a9e50b87940"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentence Alignment and Similarity:\n",
            "\n",
            "Doc1 [0]: artificial intelligence is a branch of computer science\n",
            "Doc2 [0]: artificial intelligence is a field of computer science\n",
            "Similarity: 89.09% Potential Plagiarism\n",
            "------------------------------------------------------------\n",
            "Doc1 [1]: it deals with creating intelligent agents\n",
            "Doc2 [1]: it focuses on creating smart agents\n",
            "Similarity: 53.66% \n",
            "------------------------------------------------------------\n",
            "Doc1 [2]: agents perceive their environment and take actions\n",
            "Doc2 [2]: agents perceive environment and act accordingly\n",
            "Similarity: 66.00% \n",
            "------------------------------------------------------------\n",
            "Doc1 [3]: ai includes machine learning and deep learning\n",
            "Doc2 [3]: ai covers machine learning and deep learning\n",
            "Similarity: 86.96% Potential Plagiarism\n",
            "------------------------------------------------------------\n",
            "\n",
            "Overall Plagiarism Percentage: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SfndGJQOnAiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7J9rQ-GTnAlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KP_siPqAnAoo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}